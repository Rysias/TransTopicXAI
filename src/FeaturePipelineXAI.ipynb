{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Bringing it all together!\r\n",
    "This notebook is intended for bringing together the pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import random\r\n",
    "import pickle\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from sklearn.metrics.pairwise import cosine_similarity\r\n",
    "from scipy import spatial\r\n",
    "from umap import UMAP\r\n",
    "from bertopic import BERTopic\r\n",
    "from pathlib import Path"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def weighted_mean(X, weights):\r\n",
    "    return np.dot(X.T, weights) / np.sum(weights)\r\n",
    "\r\n",
    "\r\n",
    "def get_unique_topics(topic_model):\r\n",
    "    topic_info = topic_model.get_topic_info()\r\n",
    "    return topic_info[\"Topic\"].unique()\r\n",
    "\r\n",
    "\r\n",
    "def get_topic_range(topic_model):\r\n",
    "    topic_info = topic_model.get_topic_info()\r\n",
    "    max_topic = np.max(topic_info[\"Topic\"])\r\n",
    "    return list(range(0, max_topic+1))\r\n",
    "    \r\n",
    "\r\n",
    "def find_centroid(embeddings: np.ndarray, topics: np.ndarray, probs: np.ndarray, target_topic: int):\r\n",
    "    \"\"\"\r\n",
    "    Arguments:\r\n",
    "        embeddings: 2d with dimensions (num_documents, num_dimensions)\r\n",
    "        topics: list of length num documents\r\n",
    "        probs: np.array of length num_documents showing the probability of the assigned topic\r\n",
    "        target_topic: the topic, we want to find the centroid for\r\n",
    "    returns: \r\n",
    "        The centroid for the cluster\r\n",
    "    \"\"\"\r\n",
    "    # Filtering the embeddings\r\n",
    "    filtered_embeddings = embeddings[topics == target_topic, :]\r\n",
    "    filtered_probs = probs[topics == target_topic]\r\n",
    "\r\n",
    "    # Calculating the centroid\r\n",
    "    return weighted_mean(filtered_embeddings, filtered_probs)\r\n",
    "\r\n",
    "def calc_cosine_sim(centroids, embedding):\r\n",
    "    \"\"\" \r\n",
    "    Calculates the cosine similarity between a single embedding and the centroids\r\n",
    "    \"\"\"\r\n",
    "    return cosine_similarity(centroids, embedding.reshape(1, -1))\r\n",
    "\r\n",
    "def read_pickle(file_path):\r\n",
    "    with open(file_path, \"rb\") as f:\r\n",
    "        return pickle.load(f)\r\n",
    "\r\n",
    "def flatten_embeddings(embedding_dict):\r\n",
    "    \"\"\" Creates a big matrix with all the embeddings from the dict \"\"\"\r\n",
    "    return np.vstack(embedding_dict.values())\r\n",
    "\r\n",
    "def featurize_document(doc_embeddings, centroids):\r\n",
    "    \"\"\" Calculates similarity to centroids for a document\r\n",
    "    Arguments: \r\n",
    "        doc_embeddings (np.array): the paragraph embeddings for the document with shape (n_paragraphs, embedding_dim)\r\n",
    "        centroids (np.array): centroid embeddings with shape (n_topics, embedding_dim)\r\n",
    "    returns: \r\n",
    "        np.array of size (n_topics, ) with the\r\n",
    "    \"\"\"\r\n",
    "    return np.mean(cosine_similarity(doc_embeddings, centroids), axis=0)\r\n",
    "\r\n",
    "def remove_empty_embeddings(embedding_dict):\r\n",
    "    return {k: v for k, v in embedding_dict.items() if v.shape[0] != 0}\r\n",
    "\r\n",
    "    \r\n",
    "def find_closest_index(featurized_doc, tree):\r\n",
    "    \"\"\" Returns the tree index of nearest neighbour of a document \"\"\"\r\n",
    "    return tree.query(featurized_doc, 2)[1][1]\r\n",
    "\r\n",
    "def index_to_key(idx, index_dict):\r\n",
    "    return index_dict[idx]\r\n",
    "\r\n",
    "\r\n",
    "def get_best_match(feautrized_doc, tree, index_dict):\r\n",
    "    closest_index = find_closest_index(feautrized_doc, tree)\r\n",
    "    return index_to_key(closest_index, index_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Loading data\r\n",
    "DATA_DIR = Path(\"../../BscThesisData/data\")\r\n",
    "doc_topics = pd.read_csv(DATA_DIR / \"doc_topics.csv\")\r\n",
    "embeddings_dict = read_pickle(DATA_DIR / \"embedding_dict.pkl\")\r\n",
    "\r\n",
    "embeddings = flatten_embeddings(embeddings_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Loading topic model\r\n",
    "MODEL_PATH = Path(\"../models/topic_model\")\r\n",
    "topic_model = BERTopic.load(str(MODEL_PATH), embedding_model=\"Maltehb/-l-ctra-danish-electra-small-cased\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:root:No sentence-transformers model found with name C:\\Users\\jhr/.cache\\torch\\sentence_transformers\\Maltehb_-l-ctra-danish-electra-small-cased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\jhr/.cache\\torch\\sentence_transformers\\Maltehb_-l-ctra-danish-electra-small-cased were not used when initializing ElectraModel: ['generator.encoder.layer.8.attention.self.key.weight', 'generator.encoder.layer.1.attention.self.key.weight', 'generator.encoder.layer.9.output.dense.bias', 'generator.embeddings_project.bias', 'generator.encoder.layer.8.output.dense.bias', 'generator.encoder.layer.10.attention.self.key.bias', 'generator.encoder.layer.5.attention.output.LayerNorm.bias', 'generator.encoder.layer.5.output.LayerNorm.bias', 'generator.encoder.layer.9.attention.output.LayerNorm.weight', 'generator.encoder.layer.6.attention.output.LayerNorm.weight', 'discriminator_predictions.dense.weight', 'generator.encoder.layer.0.attention.output.dense.bias', 'generator.encoder.layer.3.attention.output.dense.bias', 'generator.encoder.layer.4.output.dense.bias', 'discriminator_predictions.LayerNorm.weight', 'generator.encoder.layer.4.attention.output.dense.weight', 'generator.encoder.layer.10.intermediate.dense.weight', 'generator.encoder.layer.7.attention.self.query.weight', 'generator.encoder.layer.7.output.dense.weight', 'generator.encoder.layer.6.attention.self.value.bias', 'generator.encoder.layer.8.output.LayerNorm.bias', 'generator.encoder.layer.10.output.LayerNorm.weight', 'generator.encoder.layer.4.attention.output.LayerNorm.weight', 'generator.encoder.layer.0.intermediate.dense.weight', 'generator.encoder.layer.9.attention.output.dense.weight', 'generator.encoder.layer.0.attention.output.LayerNorm.bias', 'generator.encoder.layer.11.output.LayerNorm.bias', 'generator.encoder.layer.5.attention.output.LayerNorm.weight', 'discriminator_predictions.dense.bias', 'generator.encoder.layer.9.attention.self.query.bias', 'discriminator_predictions.classifier.bias', 'generator.encoder.layer.11.attention.self.query.weight', 'generator.encoder.layer.2.attention.output.LayerNorm.weight', 'generator.encoder.layer.4.attention.self.value.bias', 'generator.encoder.layer.7.output.LayerNorm.bias', 'generator.encoder.layer.4.attention.self.value.weight', 'generator.encoder.layer.8.output.LayerNorm.weight', 'generator_predictions.decoder.bias', 'generator.encoder.layer.1.attention.output.dense.weight', 'generator.encoder.layer.11.attention.output.LayerNorm.bias', 'generator_predictions.decoder.weight', 'generator.encoder.layer.9.intermediate.dense.bias', 'generator.embeddings.LayerNorm.weight', 'generator.encoder.layer.11.attention.self.key.weight', 'generator.encoder.layer.5.attention.self.value.weight', 'generator.encoder.layer.1.attention.output.LayerNorm.weight', 'generator.encoder.layer.0.attention.self.query.weight', 'generator.encoder.layer.7.attention.output.LayerNorm.bias', 'generator.encoder.layer.7.intermediate.dense.weight', 'generator.encoder.layer.9.attention.output.LayerNorm.bias', 'generator.encoder.layer.4.intermediate.dense.bias', 'generator.encoder.layer.3.intermediate.dense.bias', 'generator.encoder.layer.1.attention.self.value.bias', 'generator.encoder.layer.10.intermediate.dense.bias', 'generator.encoder.layer.3.attention.output.LayerNorm.bias', 'generator.encoder.layer.2.attention.output.dense.weight', 'generator.encoder.layer.3.attention.self.value.weight', 'generator.encoder.layer.6.attention.output.LayerNorm.bias', 'generator.encoder.layer.5.attention.self.key.weight', 'generator.encoder.layer.0.intermediate.dense.bias', 'generator.encoder.layer.10.attention.self.key.weight', 'generator.embeddings_project.weight', 'generator.encoder.layer.7.attention.self.value.weight', 'generator.encoder.layer.7.attention.output.dense.weight', 'generator.encoder.layer.5.output.LayerNorm.weight', 'generator.encoder.layer.2.attention.self.query.weight', 'generator.encoder.layer.3.output.dense.weight', 'generator.encoder.layer.3.attention.output.LayerNorm.weight', 'generator.encoder.layer.1.attention.self.key.bias', 'generator.encoder.layer.2.attention.self.query.bias', 'generator.encoder.layer.2.output.dense.bias', 'generator.encoder.layer.10.attention.output.LayerNorm.bias', 'generator.encoder.layer.2.attention.output.LayerNorm.bias', 'generator.encoder.layer.2.attention.self.key.bias', 'generator.encoder.layer.8.attention.self.value.bias', 'generator.encoder.layer.11.intermediate.dense.weight', 'generator.encoder.layer.4.attention.output.dense.bias', 'generator.encoder.layer.5.intermediate.dense.weight', 'generator.encoder.layer.2.output.LayerNorm.bias', 'generator.encoder.layer.6.attention.output.dense.bias', 'generator.encoder.layer.5.output.dense.weight', 'generator.encoder.layer.9.attention.self.key.weight', 'generator.encoder.layer.3.output.dense.bias', 'generator.encoder.layer.8.attention.self.value.weight', 'generator.encoder.layer.5.attention.self.query.weight', 'generator.embeddings.token_type_embeddings.weight', 'generator.encoder.layer.4.intermediate.dense.weight', 'generator_predictions.dense.bias', 'generator.encoder.layer.10.attention.self.value.weight', 'generator.encoder.layer.8.attention.output.LayerNorm.weight', 'generator.encoder.layer.11.attention.output.dense.bias', 'generator.encoder.layer.4.output.LayerNorm.bias', 'generator.encoder.layer.2.attention.self.value.bias', 'generator.encoder.layer.9.attention.self.value.weight', 'generator.encoder.layer.2.output.LayerNorm.weight', 'generator.encoder.layer.3.attention.self.key.weight', 'generator.encoder.layer.5.attention.self.value.bias', 'generator.encoder.layer.0.output.dense.bias', 'generator.embeddings.LayerNorm.bias', 'generator.encoder.layer.6.attention.self.query.weight', 'generator.encoder.layer.5.attention.self.key.bias', 'generator.encoder.layer.6.output.LayerNorm.bias', 'generator_predictions.LayerNorm.bias', 'generator.encoder.layer.5.intermediate.dense.bias', 'generator.encoder.layer.8.output.dense.weight', 'generator.encoder.layer.11.intermediate.dense.bias', 'generator.encoder.layer.0.attention.self.value.weight', 'generator.encoder.layer.0.output.dense.weight', 'generator.encoder.layer.4.attention.self.query.weight', 'generator_predictions.bias', 'generator.encoder.layer.2.intermediate.dense.bias', 'generator.encoder.layer.8.attention.output.dense.bias', 'generator.encoder.layer.0.attention.self.query.bias', 'generator.encoder.layer.6.intermediate.dense.bias', 'generator.encoder.layer.2.attention.self.value.weight', 'generator_predictions.LayerNorm.weight', 'generator.encoder.layer.4.output.LayerNorm.weight', 'generator.encoder.layer.7.intermediate.dense.bias', 'generator.encoder.layer.3.attention.self.query.weight', 'generator.encoder.layer.11.attention.self.query.bias', 'discriminator_predictions.classifier.weight', 'generator.encoder.layer.0.attention.output.LayerNorm.weight', 'generator.encoder.layer.5.attention.output.dense.bias', 'generator.encoder.layer.6.output.LayerNorm.weight', 'generator.encoder.layer.9.attention.self.query.weight', 'generator.encoder.layer.10.attention.output.dense.bias', 'generator.encoder.layer.10.output.LayerNorm.bias', 'generator.encoder.layer.5.output.dense.bias', 'generator.encoder.layer.9.output.LayerNorm.weight', 'generator.encoder.layer.11.output.LayerNorm.weight', 'generator.embeddings.position_embeddings.weight', 'generator.encoder.layer.6.attention.self.key.weight', 'generator.encoder.layer.1.attention.output.LayerNorm.bias', 'generator.encoder.layer.5.attention.output.dense.weight', 'generator.encoder.layer.9.attention.output.dense.bias', 'generator.encoder.layer.3.attention.self.key.bias', 'generator.encoder.layer.4.attention.self.query.bias', 'generator.encoder.layer.11.output.dense.weight', 'generator.encoder.layer.8.attention.self.query.weight', 'generator.encoder.layer.6.attention.self.value.weight', 'generator.encoder.layer.7.attention.output.dense.bias', 'generator.encoder.layer.6.output.dense.weight', 'generator.encoder.layer.9.output.dense.weight', 'generator.encoder.layer.8.attention.self.query.bias', 'generator.encoder.layer.0.output.LayerNorm.weight', 'generator.encoder.layer.0.attention.self.value.bias', 'generator.encoder.layer.11.output.dense.bias', 'generator.encoder.layer.10.attention.self.query.bias', 'generator.encoder.layer.1.attention.self.value.weight', 'generator.encoder.layer.10.attention.output.dense.weight', 'generator.encoder.layer.3.attention.self.query.bias', 'generator.encoder.layer.3.intermediate.dense.weight', 'generator.encoder.layer.11.attention.output.dense.weight', 'generator.encoder.layer.11.attention.self.value.weight', 'generator.encoder.layer.0.output.LayerNorm.bias', 'generator.encoder.layer.7.attention.output.LayerNorm.weight', 'generator.encoder.layer.3.attention.output.dense.weight', 'generator.encoder.layer.3.output.LayerNorm.weight', 'generator.encoder.layer.7.attention.self.query.bias', 'generator.encoder.layer.1.output.LayerNorm.weight', 'generator.encoder.layer.6.output.dense.bias', 'generator.encoder.layer.11.attention.output.LayerNorm.weight', 'generator.encoder.layer.1.attention.output.dense.bias', 'generator.encoder.layer.5.attention.self.query.bias', 'generator.encoder.layer.8.attention.self.key.bias', 'generator.encoder.layer.9.output.LayerNorm.bias', 'generator.encoder.layer.1.intermediate.dense.weight', 'generator.encoder.layer.1.attention.self.query.weight', 'generator.encoder.layer.10.output.dense.weight', 'discriminator_predictions.LayerNorm.bias', 'generator.encoder.layer.2.intermediate.dense.weight', 'generator.encoder.layer.3.output.LayerNorm.bias', 'generator.encoder.layer.0.attention.output.dense.weight', 'generator.encoder.layer.1.attention.self.query.bias', 'generator.encoder.layer.6.attention.output.dense.weight', 'generator.encoder.layer.1.output.LayerNorm.bias', 'generator.encoder.layer.2.attention.self.key.weight', 'generator.encoder.layer.4.attention.output.LayerNorm.bias', 'generator.encoder.layer.2.attention.output.dense.bias', 'generator.encoder.layer.8.intermediate.dense.weight', 'generator.encoder.layer.4.output.dense.weight', 'generator.encoder.layer.1.output.dense.weight', 'generator.encoder.layer.9.attention.self.value.bias', 'generator.encoder.layer.1.intermediate.dense.bias', 'generator.encoder.layer.1.output.dense.bias', 'generator.encoder.layer.0.attention.self.key.bias', 'generator.embeddings.word_embeddings.weight', 'generator.encoder.layer.6.attention.self.query.bias', 'generator.encoder.layer.9.attention.self.key.bias', 'generator.encoder.layer.10.output.dense.bias', 'generator.encoder.layer.8.attention.output.dense.weight', 'generator.encoder.layer.11.attention.self.value.bias', 'generator.encoder.layer.0.attention.self.key.weight', 'generator.encoder.layer.2.output.dense.weight', 'generator.encoder.layer.9.intermediate.dense.weight', 'generator.encoder.layer.6.attention.self.key.bias', 'generator.encoder.layer.4.attention.self.key.weight', 'generator_predictions.dense.weight', 'generator.encoder.layer.7.attention.self.key.weight', 'generator.encoder.layer.6.intermediate.dense.weight', 'generator.encoder.layer.8.intermediate.dense.bias', 'generator.encoder.layer.7.attention.self.key.bias', 'generator.encoder.layer.11.attention.self.key.bias', 'generator.encoder.layer.3.attention.self.value.bias', 'generator.encoder.layer.7.output.dense.bias', 'generator.encoder.layer.7.attention.self.value.bias', 'generator.encoder.layer.4.attention.self.key.bias', 'generator.encoder.layer.10.attention.self.value.bias', 'generator.encoder.layer.8.attention.output.LayerNorm.bias', 'generator.encoder.layer.7.output.LayerNorm.weight', 'generator.encoder.layer.10.attention.output.LayerNorm.weight', 'generator.encoder.layer.10.attention.self.query.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "topics = doc_topics[\"topic\"].values\r\n",
    "probs = doc_topics[\"prob\"].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "unique_topics = get_topic_range(topic_model)\r\n",
    "centroids = np.zeros((len(unique_topics),embeddings.shape[1])) # Centroids need dimensions (number of topics, embedding-dimensionality)\r\n",
    "for i in unique_topics:\r\n",
    "    centroids[i, :] += find_centroid(embeddings, topics, probs, i)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "centroids.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5, 256)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pipeline for calculating features\r\n",
    "1. Calculate centroids\r\n",
    "2. Calculate paragraph-centroid similarity for each paragraph (in embedding_dict)\r\n",
    "3. average the similarities "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Steps 2 and 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# add centroid similarity array to dict\r\n",
    "filtered_embedding_dict = remove_empty_embeddings(embeddings_dict)\r\n",
    "embeddings_dict_new = {k: {\"raw\": v, \"dist\": featurize_document(v, centroids)} for k, v in filtered_embedding_dict.items()}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "example_key = \"D_2298497\"\r\n",
    "example_embedding = embeddings_dict[example_key]\r\n",
    "print(embeddings_dict_new[example_key][\"dist\"].shape)\r\n",
    "print(example_embedding.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5,)\n",
      "(4, 256)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "cosine_similarity(example_embedding, centroids).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Finding nearest neighbours \r\n",
    "Following [this SO](https://stackoverflow.com/a/32446753)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Create flat feature structure \r\n",
    "doc_features = np.vstack((v[\"dist\"] for v in embeddings_dict_new.values()))\r\n",
    "assert doc_features.shape[1] == len(unique_topics)\r\n",
    "\r\n",
    "# create KDTree\r\n",
    "tree = spatial.KDTree(doc_features)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Note on structure!\r\n",
    "It's becoming a bit of a pain not having proper indeces, so I might have to change the embedding dict to have some numerical keys \r\n",
    "This could feasibly be an extra key or evt. change it to a pd.DataFrame. Alternatively, I  couuld just have a doc-index dict (which is easier to create)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "doc_index_dict = {i: doc_id for i, doc_id in enumerate(embeddings_dict_new.keys())}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "get_best_match(doc_features[0], tree, doc_index_dict)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'D_2242034'"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "doc_features[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.95962622, 0.9569056 , 0.07983996, 0.92299301, 0.86310622])"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experimenting with the shizzle\r\n",
    "NB: The embeddings haven't been updated yet, so results might vary\r\n",
    "\r\n",
    "Let's sanity check some of these delicious matches"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Loading data\r\n",
    "paragraph_dict = read_pickle(DATA_DIR / \"paragraph_dict.pkl\")\r\n",
    "print(paragraph_dict[example_key])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Sagen angik en skønsmæssig forhøjelse af sagsøgerens skattepligtige indkomst for indkomstårene 2013 og 2014, som skattemyndighederne havde foretaget på grundlag af en privatforbrugsopgørelse for sagsøgerens husstand, der udviste et negativt privatforbrug for husstanden i de pågældende indkomstår. ', 'Retten fandt det ikke godtgjort, at sagsøgeren i årene 2000-2012 havde sparet 600.000-700.000 kr. op i kontanter, som han havde brugt til at finansiere sit privatforbrug i 2013 og 2014. ', 'Retten fandt det heller ikke godtgjort, at SKATs skønsmæssige ansættelse af husstandens privatforbrug, som var baseret på dels faktiske konstaterede udgifter, dels et skøn, var fastsat for højt. ', 'Endelig fandt retten det ikke godtgjort, at en del af den skønsmæssige forhøjelse, som var foretaget på baggrund af en opgørelse af husstandens privatforbrug, skulle henføres til sagsøgerens ægtefælle og ikke som sket udelukkende til sagsøgeren. ']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "i = 0\r\n",
    "for doc_id, items in embeddings_dict_new.items():\r\n",
    "    if i > 2:\r\n",
    "        break\r\n",
    "    doc_features = items[\"dist\"]\r\n",
    "    print(f\"query text: {paragraph_dict[doc_id]}\")\r\n",
    "    best_match_id = get_best_match(doc_features, tree, doc_index_dict)\r\n",
    "    print(f\"matches with {best_match_id}\")\r\n",
    "    print(paragraph_dict[best_match_id])\r\n",
    "    print(\"\\n\")\r\n",
    "    i += 1"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "query text: ['Sagen angik en skønsmæssig forhøjelse af sagsøgerens skattepligtige indkomst for indkomstårene 2013 og 2014, som skattemyndighederne havde foretaget på grundlag af en privatforbrugsopgørelse for sagsøgerens husstand, der udviste et negativt privatforbrug for husstanden i de pågældende indkomstår. ', 'Retten fandt det ikke godtgjort, at sagsøgeren i årene 2000-2012 havde sparet 600.000-700.000 kr. op i kontanter, som han havde brugt til at finansiere sit privatforbrug i 2013 og 2014. ', 'Retten fandt det heller ikke godtgjort, at SKATs skønsmæssige ansættelse af husstandens privatforbrug, som var baseret på dels faktiske konstaterede udgifter, dels et skøn, var fastsat for højt. ', 'Endelig fandt retten det ikke godtgjort, at en del af den skønsmæssige forhøjelse, som var foretaget på baggrund af en opgørelse af husstandens privatforbrug, skulle henføres til sagsøgerens ægtefælle og ikke som sket udelukkende til sagsøgeren. ']\n",
      "matches with D_2242034\n",
      "['Sagsøgerne et selskab og selskabets eneaktionær havde indbragt to landsskatteretskendelser for domstolene angående deres skattepligtige indkomster for 2007 og 2008. Sagerne blev behandlet samlet.', 'Sagen mod eneaktionæren handlede om, hvorvidt denne havde fået stillet en Ferrari og en Lamborghini til rådighed af selskabet, og derfor skulle beskattes af værdien af rådighed over fri bil i medfør af ligningslovens § 16, stk. 4. Herudover handlede sagen om, hvorvidt eneaktionæren havde dokumenteret, at en række udgifter afholdt i selskabet relaterede sig til selskabets drift, eller om udgifterne reelt var private udgifter, som skulle anses for maskeret udlodning til eneaktionæren, jf. ligningslovens § 16 A, stk. 1.', 'Retten fandt, at der samlet set var en sådan usikkerhed om brugen af bilerne, at det ikke var godtgjort, at eneaktionæren havde været afskåret fra at råde over bilerne. Retten fandt derfor, at eneaktionæren skulle beskattes af værdien af rådighed over fri bil i medfør af ligningslovens § 16, stk. 4. For så vidt angår spørgsmålet om maskeret udlodning fandt retten, at to Corvetter indkøbt af selskabet, skulle anses for fradragsberettigede investeringsaktiver for selskabet, og at der ved forklaringer og bilag var fremlagt tilstrækkelig dokumentation for at anerkende udgifter på kr. 79.833, som fradragsberettigede udgifter i 2007. For så vidt angik de øvrige påberåbte udgifter fandt retten, at der hverken gennem bilag eller forklaringer forelå tilstrækkelig dokumentation for, at der havde været tale om anerkendelsesværdige selskabsudgifter. Retten fandt derfor, at de resterende påberåbte udgifter var maskerede udlodninger til eneaktionæren.', 'Sagen mod selskabet handlede om, hvorvidt selskabet havde dokumenteret, at udgifter afholdt i 2007 og 2008 angik selskabets drift og at selskabet derfor havde ret til at fradrage udgifter i selskabets skattepligtige indkomst, samt hvorvidt selskabet havde ret til at forhøje saldoen på selskabets afskrivningskonto for driftsmidler. Herudover handlede sagen om, hvorvidt selskabet havde modtaget et skattepligtigt tilskud.', 'Retten fandt, at der hverken gennem bilag eller forklaringer forelå tilstrækkelig dokumentation for, at udgifter afholdt i selskabet skulle anses for anerkendelsesværdige selskabsudgifter. Selskabet havde derfor ikke ret til fradrag for driftsudgifter i medfør af statsskattelovens § 6, stk. 1, litra a, og de bogførte udgifter på selskabets driftsmiddelkonto kunne ikke anerkendes som vedrørende afskrivningsberettigede driftsmidler. Retten fandt dog, at selskabet med henvisning til eneaktionærens sag skulle tilkendes fradragsret for kr. 79.833, vedrørende driftsinventar.', 'Herudover fandt retten, at afgivne forklaringer ikke på fyldestgørende vis afkræftede den formodning, der efter forskellige posteringer bestod for, at selskabet havde modtaget et skattepligtigt tilskud.', 'I begge sager havde sagsøgerne nedlagt principal påstand om ophævelse af SKATs afgørelser med henvisning til, at fristen i skatteforvaltningslovens § 26, stk. 1, ikke var overholdt. Retten fandt i relation hertil, at der ikke var grundlag for sagsøgernes fortolkning af reglerne derhen, at endelig ansættelse skulle foreligge inden for tre måneder efter varslingen. Retten fandt herefter, at endelig ansættelse var sket inden fristerne i skatteforvaltningslovens § 26, stk. 1, 2. pkt., og skatteansættelserne var derfor rettidige og gyldige.']\n",
      "\n",
      "\n",
      "query text: ['Koncern med datterselskaber, hvis virksomhed består i at eje udlejningsejendomme samt ejendomme, der er under opførsel med henblik på udlejning til beboelse. Selskaberne køber og sælger ejendomme, der alle er udlejet før, under og efter datterselskabernes ejerskab. Udlejningsejendomme og ejendomme under opførsel med henblik på udlejning til beboelse anset for passiv kapitalanbringelse (pengetankaktiver) jf. pengetankreglen i aktieavancebeskatningslovens § 34.']\n",
      "matches with D_2296021\n",
      "['Sagen omhandler moms og vouchere. Sagen omhandler særligt, hvorvidt en ret til ombytning af en voucher med én funktionalitet - en voucher til ét formål - som kan ombyttes til en voucher med en anden funktionalitet - en voucher til flere formål - bevirker, at den første voucher af den grund også vil være en voucher til flere formål.', 'Skatterådet kan ikke anse et gavekort, som kun kan anvendes i Danmark, og som kun kan anvendes til indkøb tillagt 25% dansk moms, for at udgøre et gavekort til flere formål, hvis gavekortet indenfor gyldighedsperioden kan ombyttes til et gavekort, som kan anvendes til flere formål.', 'Skatterådet finder ikke, at det har betydning for svaret på det første spørgsmål, om ombytningen sker i forbindelse med gyldighedsperiodens udløb eller kan ske på et hvilket som helst tidspunkt indenfor gyldighedsperioden.']\n",
      "\n",
      "\n",
      "query text: ['Sagen angik, om sagsøgeren med rette var blevet beskattet af en lang række overførsler og kontantindsættelser på sagsøgerens bankkonto. Retten fastslog, at bevisbyrden - efter de anførte oplysninger om sagsøgers indtægtsforhold - påhvilede sagsøgeren. Retten fandt, at sagsøgeren hverken havde godtgjort, at indsættelserne udgjorde lån, som var ydet til ham af en række personer i det Y1-land miljø, eller donationer til Y1-land Forening. ', 'Sagen angik endvidere, om sagsøgeren med rette var blevet beskattet af en række foretagne valutavekslinger. Retten lagde til grund, at de pågældene vekslinger var foretaget af sagsøgeren. Efter vekslinger- nes beløbsmæssige størrelser sammenholdt med oplysninger om sagsøgers beregnede privatforbrug, fandt retten, at skattemyndighederne havde haft fornødent grundlag for at foretage den omhandlede forhøjelse af sagsøgeres indkomst. ', 'Skatteministeriet blev herefter frifundet. ']\n",
      "matches with D_2095485\n",
      "['En kommune ønskede at overdrage en vand-koncern til et forbrugerejet andelsselskab. X Vand A/S, Y a.m.b.a. og Z a.m.b.a. var registreret efter tre forskellige skattepligtsbestemmelser, og en fastlagt transaktionsmodel ønskedes derfor afklaret. Z a.m.b.a. var beskattet efter SEL § 1, stk. 1, nr. 2h. Det var oplyst, at Z a.m.b.a. ikke var registreret som omfattet af lov om erhvervsdrivende virksomheder § 3, og Skatterådet fandt dermed ikke, at Z a.m.b.a. var omfattet af SEL § 1, stk. 1, nr. 2. Under forudsætning af, at der blev opnået tilladelse fra SKAT til en skattefri tilførsel af aktiver af hele aktiviteten fra Z a.m.b.a. til et nystiftet selskab, bekræftede Skatterådet derfor, at Z a.m.b.a. ved tilførslen ville overgå til beskatning efter SEL § 1, stk. 1, nr. 6. Da skattepligt efter SEL § 1, stk. 1, nr. 6, kun omfatter indtægt ved erhvervsmæssig virksomhed, bekræftede Skatterådet videre, at Z a.m.b.a. ikke var skattepligtig af et tilskud i form af aktierne i X Vand A/S ydet af kommunen og af et tilskud i form af aktierne i Y A/S ydet af Y a.m.b.a.']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('bertopic_explore': conda)"
  },
  "interpreter": {
   "hash": "d6f86e4359b2b5cf5d398b363c816bb50d8f4fd2c9e9291492e7c9219700f63c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}