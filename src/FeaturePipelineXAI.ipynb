{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bringing it all together!\n",
    "This notebook is intended for bringing together the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "from umap import UMAP\n",
    "from bertopic import BERTopic\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean(X, weights):\n",
    "    return np.dot(X.T, weights) / np.sum(weights)\n",
    "\n",
    "\n",
    "def get_unique_topics(topic_model):\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    return topic_info[\"Topic\"].unique()\n",
    "\n",
    "\n",
    "def get_topic_range(topic_model):\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    max_topic = np.max(topic_info[\"Topic\"])\n",
    "    return list(range(0, max_topic+1))\n",
    "    \n",
    "\n",
    "def find_centroid(embeddings: np.ndarray, topics: np.ndarray, probs: np.ndarray, target_topic: int):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        embeddings: 2d with dimensions (num_documents, num_dimensions)\n",
    "        topics: list of length num documents\n",
    "        probs: np.array of length num_documents showing the probability of the assigned topic\n",
    "        target_topic: the topic, we want to find the centroid for\n",
    "    returns: \n",
    "        The centroid for the cluster\n",
    "    \"\"\"\n",
    "    # Filtering the embeddings\n",
    "    filtered_embeddings = embeddings[topics == target_topic, :]\n",
    "    filtered_probs = probs[topics == target_topic]\n",
    "\n",
    "    # Calculating the centroid\n",
    "    return weighted_mean(filtered_embeddings, filtered_probs)\n",
    "\n",
    "def calc_cosine_sim(centroids, embedding):\n",
    "    \"\"\" \n",
    "    Calculates the cosine similarity between a single embedding and the centroids\n",
    "    \"\"\"\n",
    "    return cosine_similarity(centroids, embedding.reshape(1, -1))\n",
    "\n",
    "def read_pickle(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def flatten_embeddings(embedding_dict):\n",
    "    \"\"\" Creates a big matrix with all the embeddings from the dict \"\"\"\n",
    "    return np.vstack(embedding_dict.values())\n",
    "\n",
    "def featurize_document(doc_embeddings, centroids):\n",
    "    \"\"\" Calculates similarity to centroids for a document\n",
    "    Arguments: \n",
    "        doc_embeddings (np.array): the paragraph embeddings for the document with shape (n_paragraphs, embedding_dim)\n",
    "        centroids (np.array): centroid embeddings with shape (n_topics, embedding_dim)\n",
    "    returns: \n",
    "        np.array of size (n_topics, ) with the\n",
    "    \"\"\"\n",
    "    return np.mean(cosine_similarity(doc_embeddings, centroids), axis=0)\n",
    "\n",
    "def remove_empty_embeddings(embedding_dict):\n",
    "    return {k: v for k, v in embedding_dict.items() if v.shape[0] != 0}\n",
    "\n",
    "    \n",
    "def find_closest_index(featurized_doc, tree):\n",
    "    \"\"\" Returns the tree index of nearest neighbour of a document \"\"\"\n",
    "    return tree.query(featurized_doc, 2)[1][1]\n",
    "\n",
    "def index_to_key(idx, index_dict):\n",
    "    return index_dict[idx]\n",
    "\n",
    "\n",
    "def get_best_match(feautrized_doc, tree, index_dict):\n",
    "    closest_index = find_closest_index(feautrized_doc, tree)\n",
    "    return index_to_key(closest_index, index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "DATA_DIR = Path(\"../../BscThesisData/data\")\n",
    "doc_topics = pd.read_csv(DATA_DIR / \"doc_topics.csv\")\n",
    "embeddings_dict = read_pickle(DATA_DIR / \"embedding_dict.pkl\")\n",
    "\n",
    "embeddings = flatten_embeddings(embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No sentence-transformers model found with name C:\\Users\\jhr/.cache\\torch\\sentence_transformers\\Maltehb_-l-ctra-danish-electra-small-cased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\jhr/.cache\\torch\\sentence_transformers\\Maltehb_-l-ctra-danish-electra-small-cased were not used when initializing ElectraModel: ['generator.encoder.layer.8.attention.self.key.weight', 'generator.encoder.layer.1.attention.self.key.weight', 'generator.encoder.layer.9.output.dense.bias', 'generator.embeddings_project.bias', 'generator.encoder.layer.8.output.dense.bias', 'generator.encoder.layer.10.attention.self.key.bias', 'generator.encoder.layer.5.attention.output.LayerNorm.bias', 'generator.encoder.layer.5.output.LayerNorm.bias', 'generator.encoder.layer.9.attention.output.LayerNorm.weight', 'generator.encoder.layer.6.attention.output.LayerNorm.weight', 'discriminator_predictions.dense.weight', 'generator.encoder.layer.0.attention.output.dense.bias', 'generator.encoder.layer.3.attention.output.dense.bias', 'generator.encoder.layer.4.output.dense.bias', 'discriminator_predictions.LayerNorm.weight', 'generator.encoder.layer.4.attention.output.dense.weight', 'generator.encoder.layer.10.intermediate.dense.weight', 'generator.encoder.layer.7.attention.self.query.weight', 'generator.encoder.layer.7.output.dense.weight', 'generator.encoder.layer.6.attention.self.value.bias', 'generator.encoder.layer.8.output.LayerNorm.bias', 'generator.encoder.layer.10.output.LayerNorm.weight', 'generator.encoder.layer.4.attention.output.LayerNorm.weight', 'generator.encoder.layer.0.intermediate.dense.weight', 'generator.encoder.layer.9.attention.output.dense.weight', 'generator.encoder.layer.0.attention.output.LayerNorm.bias', 'generator.encoder.layer.11.output.LayerNorm.bias', 'generator.encoder.layer.5.attention.output.LayerNorm.weight', 'discriminator_predictions.dense.bias', 'generator.encoder.layer.9.attention.self.query.bias', 'discriminator_predictions.classifier.bias', 'generator.encoder.layer.11.attention.self.query.weight', 'generator.encoder.layer.2.attention.output.LayerNorm.weight', 'generator.encoder.layer.4.attention.self.value.bias', 'generator.encoder.layer.7.output.LayerNorm.bias', 'generator.encoder.layer.4.attention.self.value.weight', 'generator.encoder.layer.8.output.LayerNorm.weight', 'generator_predictions.decoder.bias', 'generator.encoder.layer.1.attention.output.dense.weight', 'generator.encoder.layer.11.attention.output.LayerNorm.bias', 'generator_predictions.decoder.weight', 'generator.encoder.layer.9.intermediate.dense.bias', 'generator.embeddings.LayerNorm.weight', 'generator.encoder.layer.11.attention.self.key.weight', 'generator.encoder.layer.5.attention.self.value.weight', 'generator.encoder.layer.1.attention.output.LayerNorm.weight', 'generator.encoder.layer.0.attention.self.query.weight', 'generator.encoder.layer.7.attention.output.LayerNorm.bias', 'generator.encoder.layer.7.intermediate.dense.weight', 'generator.encoder.layer.9.attention.output.LayerNorm.bias', 'generator.encoder.layer.4.intermediate.dense.bias', 'generator.encoder.layer.3.intermediate.dense.bias', 'generator.encoder.layer.1.attention.self.value.bias', 'generator.encoder.layer.10.intermediate.dense.bias', 'generator.encoder.layer.3.attention.output.LayerNorm.bias', 'generator.encoder.layer.2.attention.output.dense.weight', 'generator.encoder.layer.3.attention.self.value.weight', 'generator.encoder.layer.6.attention.output.LayerNorm.bias', 'generator.encoder.layer.5.attention.self.key.weight', 'generator.encoder.layer.0.intermediate.dense.bias', 'generator.encoder.layer.10.attention.self.key.weight', 'generator.embeddings_project.weight', 'generator.encoder.layer.7.attention.self.value.weight', 'generator.encoder.layer.7.attention.output.dense.weight', 'generator.encoder.layer.5.output.LayerNorm.weight', 'generator.encoder.layer.2.attention.self.query.weight', 'generator.encoder.layer.3.output.dense.weight', 'generator.encoder.layer.3.attention.output.LayerNorm.weight', 'generator.encoder.layer.1.attention.self.key.bias', 'generator.encoder.layer.2.attention.self.query.bias', 'generator.encoder.layer.2.output.dense.bias', 'generator.encoder.layer.10.attention.output.LayerNorm.bias', 'generator.encoder.layer.2.attention.output.LayerNorm.bias', 'generator.encoder.layer.2.attention.self.key.bias', 'generator.encoder.layer.8.attention.self.value.bias', 'generator.encoder.layer.11.intermediate.dense.weight', 'generator.encoder.layer.4.attention.output.dense.bias', 'generator.encoder.layer.5.intermediate.dense.weight', 'generator.encoder.layer.2.output.LayerNorm.bias', 'generator.encoder.layer.6.attention.output.dense.bias', 'generator.encoder.layer.5.output.dense.weight', 'generator.encoder.layer.9.attention.self.key.weight', 'generator.encoder.layer.3.output.dense.bias', 'generator.encoder.layer.8.attention.self.value.weight', 'generator.encoder.layer.5.attention.self.query.weight', 'generator.embeddings.token_type_embeddings.weight', 'generator.encoder.layer.4.intermediate.dense.weight', 'generator_predictions.dense.bias', 'generator.encoder.layer.10.attention.self.value.weight', 'generator.encoder.layer.8.attention.output.LayerNorm.weight', 'generator.encoder.layer.11.attention.output.dense.bias', 'generator.encoder.layer.4.output.LayerNorm.bias', 'generator.encoder.layer.2.attention.self.value.bias', 'generator.encoder.layer.9.attention.self.value.weight', 'generator.encoder.layer.2.output.LayerNorm.weight', 'generator.encoder.layer.3.attention.self.key.weight', 'generator.encoder.layer.5.attention.self.value.bias', 'generator.encoder.layer.0.output.dense.bias', 'generator.embeddings.LayerNorm.bias', 'generator.encoder.layer.6.attention.self.query.weight', 'generator.encoder.layer.5.attention.self.key.bias', 'generator.encoder.layer.6.output.LayerNorm.bias', 'generator_predictions.LayerNorm.bias', 'generator.encoder.layer.5.intermediate.dense.bias', 'generator.encoder.layer.8.output.dense.weight', 'generator.encoder.layer.11.intermediate.dense.bias', 'generator.encoder.layer.0.attention.self.value.weight', 'generator.encoder.layer.0.output.dense.weight', 'generator.encoder.layer.4.attention.self.query.weight', 'generator_predictions.bias', 'generator.encoder.layer.2.intermediate.dense.bias', 'generator.encoder.layer.8.attention.output.dense.bias', 'generator.encoder.layer.0.attention.self.query.bias', 'generator.encoder.layer.6.intermediate.dense.bias', 'generator.encoder.layer.2.attention.self.value.weight', 'generator_predictions.LayerNorm.weight', 'generator.encoder.layer.4.output.LayerNorm.weight', 'generator.encoder.layer.7.intermediate.dense.bias', 'generator.encoder.layer.3.attention.self.query.weight', 'generator.encoder.layer.11.attention.self.query.bias', 'discriminator_predictions.classifier.weight', 'generator.encoder.layer.0.attention.output.LayerNorm.weight', 'generator.encoder.layer.5.attention.output.dense.bias', 'generator.encoder.layer.6.output.LayerNorm.weight', 'generator.encoder.layer.9.attention.self.query.weight', 'generator.encoder.layer.10.attention.output.dense.bias', 'generator.encoder.layer.10.output.LayerNorm.bias', 'generator.encoder.layer.5.output.dense.bias', 'generator.encoder.layer.9.output.LayerNorm.weight', 'generator.encoder.layer.11.output.LayerNorm.weight', 'generator.embeddings.position_embeddings.weight', 'generator.encoder.layer.6.attention.self.key.weight', 'generator.encoder.layer.1.attention.output.LayerNorm.bias', 'generator.encoder.layer.5.attention.output.dense.weight', 'generator.encoder.layer.9.attention.output.dense.bias', 'generator.encoder.layer.3.attention.self.key.bias', 'generator.encoder.layer.4.attention.self.query.bias', 'generator.encoder.layer.11.output.dense.weight', 'generator.encoder.layer.8.attention.self.query.weight', 'generator.encoder.layer.6.attention.self.value.weight', 'generator.encoder.layer.7.attention.output.dense.bias', 'generator.encoder.layer.6.output.dense.weight', 'generator.encoder.layer.9.output.dense.weight', 'generator.encoder.layer.8.attention.self.query.bias', 'generator.encoder.layer.0.output.LayerNorm.weight', 'generator.encoder.layer.0.attention.self.value.bias', 'generator.encoder.layer.11.output.dense.bias', 'generator.encoder.layer.10.attention.self.query.bias', 'generator.encoder.layer.1.attention.self.value.weight', 'generator.encoder.layer.10.attention.output.dense.weight', 'generator.encoder.layer.3.attention.self.query.bias', 'generator.encoder.layer.3.intermediate.dense.weight', 'generator.encoder.layer.11.attention.output.dense.weight', 'generator.encoder.layer.11.attention.self.value.weight', 'generator.encoder.layer.0.output.LayerNorm.bias', 'generator.encoder.layer.7.attention.output.LayerNorm.weight', 'generator.encoder.layer.3.attention.output.dense.weight', 'generator.encoder.layer.3.output.LayerNorm.weight', 'generator.encoder.layer.7.attention.self.query.bias', 'generator.encoder.layer.1.output.LayerNorm.weight', 'generator.encoder.layer.6.output.dense.bias', 'generator.encoder.layer.11.attention.output.LayerNorm.weight', 'generator.encoder.layer.1.attention.output.dense.bias', 'generator.encoder.layer.5.attention.self.query.bias', 'generator.encoder.layer.8.attention.self.key.bias', 'generator.encoder.layer.9.output.LayerNorm.bias', 'generator.encoder.layer.1.intermediate.dense.weight', 'generator.encoder.layer.1.attention.self.query.weight', 'generator.encoder.layer.10.output.dense.weight', 'discriminator_predictions.LayerNorm.bias', 'generator.encoder.layer.2.intermediate.dense.weight', 'generator.encoder.layer.3.output.LayerNorm.bias', 'generator.encoder.layer.0.attention.output.dense.weight', 'generator.encoder.layer.1.attention.self.query.bias', 'generator.encoder.layer.6.attention.output.dense.weight', 'generator.encoder.layer.1.output.LayerNorm.bias', 'generator.encoder.layer.2.attention.self.key.weight', 'generator.encoder.layer.4.attention.output.LayerNorm.bias', 'generator.encoder.layer.2.attention.output.dense.bias', 'generator.encoder.layer.8.intermediate.dense.weight', 'generator.encoder.layer.4.output.dense.weight', 'generator.encoder.layer.1.output.dense.weight', 'generator.encoder.layer.9.attention.self.value.bias', 'generator.encoder.layer.1.intermediate.dense.bias', 'generator.encoder.layer.1.output.dense.bias', 'generator.encoder.layer.0.attention.self.key.bias', 'generator.embeddings.word_embeddings.weight', 'generator.encoder.layer.6.attention.self.query.bias', 'generator.encoder.layer.9.attention.self.key.bias', 'generator.encoder.layer.10.output.dense.bias', 'generator.encoder.layer.8.attention.output.dense.weight', 'generator.encoder.layer.11.attention.self.value.bias', 'generator.encoder.layer.0.attention.self.key.weight', 'generator.encoder.layer.2.output.dense.weight', 'generator.encoder.layer.9.intermediate.dense.weight', 'generator.encoder.layer.6.attention.self.key.bias', 'generator.encoder.layer.4.attention.self.key.weight', 'generator_predictions.dense.weight', 'generator.encoder.layer.7.attention.self.key.weight', 'generator.encoder.layer.6.intermediate.dense.weight', 'generator.encoder.layer.8.intermediate.dense.bias', 'generator.encoder.layer.7.attention.self.key.bias', 'generator.encoder.layer.11.attention.self.key.bias', 'generator.encoder.layer.3.attention.self.value.bias', 'generator.encoder.layer.7.output.dense.bias', 'generator.encoder.layer.7.attention.self.value.bias', 'generator.encoder.layer.4.attention.self.key.bias', 'generator.encoder.layer.10.attention.self.value.bias', 'generator.encoder.layer.8.attention.output.LayerNorm.bias', 'generator.encoder.layer.7.output.LayerNorm.weight', 'generator.encoder.layer.10.attention.output.LayerNorm.weight', 'generator.encoder.layer.10.attention.self.query.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Loading topic model\n",
    "MODEL_PATH = Path(\"../models/topic_model\")\n",
    "topic_model = BERTopic.load(str(MODEL_PATH), embedding_model=\"Maltehb/-l-ctra-danish-electra-small-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = doc_topics[\"topic\"].values\n",
    "probs = doc_topics[\"prob\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_topics = get_topic_range(topic_model)\n",
    "centroids = np.zeros((len(unique_topics),embeddings.shape[1])) # Centroids need dimensions (number of topics, embedding-dimensionality)\n",
    "for i in unique_topics:\n",
    "    centroids[i, :] += find_centroid(embeddings, topics, probs, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 256)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline for calculating features\n",
    "1. Calculate centroids\n",
    "2. Calculate paragraph-centroid similarity for each paragraph (in embedding_dict)\n",
    "3. average the similarities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add centroid similarity array to dict\n",
    "filtered_embedding_dict = remove_empty_embeddings(embeddings_dict)\n",
    "embeddings_dict_new = {k: {\"raw\": v, \"dist\": featurize_document(v, centroids)} for k, v in filtered_embedding_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "(4, 256)\n"
     ]
    }
   ],
   "source": [
    "example_key = \"D_2298497\"\n",
    "example_embedding = embeddings_dict[example_key]\n",
    "print(embeddings_dict_new[example_key][\"dist\"].shape)\n",
    "print(example_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(example_embedding, centroids).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding nearest neighbours \n",
    "Following [this SO](https://stackoverflow.com/a/32446753)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create flat feature structure \n",
    "doc_features = np.vstack((v[\"dist\"] for v in embeddings_dict_new.values()))\n",
    "assert doc_features.shape[1] == len(unique_topics)\n",
    "\n",
    "# create KDTree\n",
    "tree = spatial.KDTree(doc_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on structure!\n",
    "It's becoming a bit of a pain not having proper indeces, so I might have to change the embedding dict to have some numerical keys \n",
    "This could feasibly be an extra key or evt. change it to a pd.DataFrame. Alternatively, I  couuld just have a doc-index dict (which is easier to create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_index_dict = {i: doc_id for i, doc_id in enumerate(embeddings_dict_new.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D_2242034'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_match(doc_features[0], tree, doc_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96871278, 0.07983996, 0.96061683, 0.86443179, 0.91594289])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_features[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with the shizzle\n",
    "NB: The embeddings haven't been updated yet, so results might vary\n",
    "\n",
    "Let's sanity check some of these delicious matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sagen angik en skønsmæssig forhøjelse af sagsøgerens skattepligtige indkomst for indkomstårene 2013 og 2014, som skattemyndighederne havde foretaget på grundlag af en privatforbrugsopgørelse for sagsøgerens husstand, der udviste et negativt privatforbrug for husstanden i de pågældende indkomstår. ', 'Retten fandt det ikke godtgjort, at sagsøgeren i årene 2000-2012 havde sparet 600.000-700.000 kr. op i kontanter, som han havde brugt til at finansiere sit privatforbrug i 2013 og 2014. ', 'Retten fandt det heller ikke godtgjort, at SKATs skønsmæssige ansættelse af husstandens privatforbrug, som var baseret på dels faktiske konstaterede udgifter, dels et skøn, var fastsat for højt. ', 'Endelig fandt retten det ikke godtgjort, at en del af den skønsmæssige forhøjelse, som var foretaget på baggrund af en opgørelse af husstandens privatforbrug, skulle henføres til sagsøgerens ægtefælle og ikke som sket udelukkende til sagsøgeren. ']\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "paragraph_dict = read_pickle(DATA_DIR / \"paragraph_dict.pkl\")\n",
    "print(paragraph_dict[example_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query text: ['Sagen angik en skønsmæssig forhøjelse af sagsøgerens skattepligtige indkomst for indkomstårene 2013 og 2014, som skattemyndighederne havde foretaget på grundlag af en privatforbrugsopgørelse for sagsøgerens husstand, der udviste et negativt privatforbrug for husstanden i de pågældende indkomstår. ', 'Retten fandt det ikke godtgjort, at sagsøgeren i årene 2000-2012 havde sparet 600.000-700.000 kr. op i kontanter, som han havde brugt til at finansiere sit privatforbrug i 2013 og 2014. ', 'Retten fandt det heller ikke godtgjort, at SKATs skønsmæssige ansættelse af husstandens privatforbrug, som var baseret på dels faktiske konstaterede udgifter, dels et skøn, var fastsat for højt. ', 'Endelig fandt retten det ikke godtgjort, at en del af den skønsmæssige forhøjelse, som var foretaget på baggrund af en opgørelse af husstandens privatforbrug, skulle henføres til sagsøgerens ægtefælle og ikke som sket udelukkende til sagsøgeren. ']\n",
      "matches with D_2242034\n",
      "['Sagsøgerne et selskab og selskabets eneaktionær havde indbragt to landsskatteretskendelser for domstolene angående deres skattepligtige indkomster for 2007 og 2008. Sagerne blev behandlet samlet.', 'Sagen mod eneaktionæren handlede om, hvorvidt denne havde fået stillet en Ferrari og en Lamborghini til rådighed af selskabet, og derfor skulle beskattes af værdien af rådighed over fri bil i medfør af ligningslovens § 16, stk. 4. Herudover handlede sagen om, hvorvidt eneaktionæren havde dokumenteret, at en række udgifter afholdt i selskabet relaterede sig til selskabets drift, eller om udgifterne reelt var private udgifter, som skulle anses for maskeret udlodning til eneaktionæren, jf. ligningslovens § 16 A, stk. 1.', 'Retten fandt, at der samlet set var en sådan usikkerhed om brugen af bilerne, at det ikke var godtgjort, at eneaktionæren havde været afskåret fra at råde over bilerne. Retten fandt derfor, at eneaktionæren skulle beskattes af værdien af rådighed over fri bil i medfør af ligningslovens § 16, stk. 4. For så vidt angår spørgsmålet om maskeret udlodning fandt retten, at to Corvetter indkøbt af selskabet, skulle anses for fradragsberettigede investeringsaktiver for selskabet, og at der ved forklaringer og bilag var fremlagt tilstrækkelig dokumentation for at anerkende udgifter på kr. 79.833, som fradragsberettigede udgifter i 2007. For så vidt angik de øvrige påberåbte udgifter fandt retten, at der hverken gennem bilag eller forklaringer forelå tilstrækkelig dokumentation for, at der havde været tale om anerkendelsesværdige selskabsudgifter. Retten fandt derfor, at de resterende påberåbte udgifter var maskerede udlodninger til eneaktionæren.', 'Sagen mod selskabet handlede om, hvorvidt selskabet havde dokumenteret, at udgifter afholdt i 2007 og 2008 angik selskabets drift og at selskabet derfor havde ret til at fradrage udgifter i selskabets skattepligtige indkomst, samt hvorvidt selskabet havde ret til at forhøje saldoen på selskabets afskrivningskonto for driftsmidler. Herudover handlede sagen om, hvorvidt selskabet havde modtaget et skattepligtigt tilskud.', 'Retten fandt, at der hverken gennem bilag eller forklaringer forelå tilstrækkelig dokumentation for, at udgifter afholdt i selskabet skulle anses for anerkendelsesværdige selskabsudgifter. Selskabet havde derfor ikke ret til fradrag for driftsudgifter i medfør af statsskattelovens § 6, stk. 1, litra a, og de bogførte udgifter på selskabets driftsmiddelkonto kunne ikke anerkendes som vedrørende afskrivningsberettigede driftsmidler. Retten fandt dog, at selskabet med henvisning til eneaktionærens sag skulle tilkendes fradragsret for kr. 79.833, vedrørende driftsinventar.', 'Herudover fandt retten, at afgivne forklaringer ikke på fyldestgørende vis afkræftede den formodning, der efter forskellige posteringer bestod for, at selskabet havde modtaget et skattepligtigt tilskud.', 'I begge sager havde sagsøgerne nedlagt principal påstand om ophævelse af SKATs afgørelser med henvisning til, at fristen i skatteforvaltningslovens § 26, stk. 1, ikke var overholdt. Retten fandt i relation hertil, at der ikke var grundlag for sagsøgernes fortolkning af reglerne derhen, at endelig ansættelse skulle foreligge inden for tre måneder efter varslingen. Retten fandt herefter, at endelig ansættelse var sket inden fristerne i skatteforvaltningslovens § 26, stk. 1, 2. pkt., og skatteansættelserne var derfor rettidige og gyldige.']\n",
      "\n",
      "\n",
      "query text: ['Koncern med datterselskaber, hvis virksomhed består i at eje udlejningsejendomme samt ejendomme, der er under opførsel med henblik på udlejning til beboelse. Selskaberne køber og sælger ejendomme, der alle er udlejet før, under og efter datterselskabernes ejerskab. Udlejningsejendomme og ejendomme under opførsel med henblik på udlejning til beboelse anset for passiv kapitalanbringelse (pengetankaktiver) jf. pengetankreglen i aktieavancebeskatningslovens § 34.']\n",
      "matches with D_2237701\n",
      "['En skatteyder, der anvendte virksomhedsskatteordningen, drev virksomhed i flere lande. Den samlede virksomhedsindkomst var negativ, men i Sverige gav virksomheden overskud, og der var betalt skat i Sverige.', 'Når en skatteyder vælger at anvende virksomhedsskatteordningen, forudsætter såvel ordlyden af som formålet med bestemmelsen i ligningslovens § 33, stk. 1, om creditlempelse, at der betales indkomstskat i Danmark af den i udlandet beskattede indkomst i virksomhedsordningen, før der foreligger en dobbeltbeskatning, som kan føre til fradrag i skatteyderens indkomstskat i Danmark.', 'Eftersom det samlede resultat af virksomhederne i virksomhedsordning var negativt, var der ikke beregnet nogen virksomhedsskat i Danmark, og der var heller ikke på anden måde svaret indkomstskat i Danmark af overskuddet i den svenske del af virksomhedsordningen. Skatteyderen kunne derfor ikke opnå creditlempelse for den i Sverige betalte skat.', 'Dette var ikke i strid med administrativ praksis, hvorved retten særligt bemærkede, at udtalelser fra to skattemedarbejdere i forbindelse med kursusafholdelse ikke kunne tillægges betydning ved fastlæggelsen af administrativ praksis.', 'Skatteministeriets blev derfor frifundet.']\n",
      "\n",
      "\n",
      "query text: ['Sagen angik, om sagsøgeren med rette var blevet beskattet af en lang række overførsler og kontantindsættelser på sagsøgerens bankkonto. Retten fastslog, at bevisbyrden - efter de anførte oplysninger om sagsøgers indtægtsforhold - påhvilede sagsøgeren. Retten fandt, at sagsøgeren hverken havde godtgjort, at indsættelserne udgjorde lån, som var ydet til ham af en række personer i det Y1-land miljø, eller donationer til Y1-land Forening. ', 'Sagen angik endvidere, om sagsøgeren med rette var blevet beskattet af en række foretagne valutavekslinger. Retten lagde til grund, at de pågældene vekslinger var foretaget af sagsøgeren. Efter vekslinger- nes beløbsmæssige størrelser sammenholdt med oplysninger om sagsøgers beregnede privatforbrug, fandt retten, at skattemyndighederne havde haft fornødent grundlag for at foretage den omhandlede forhøjelse af sagsøgeres indkomst. ', 'Skatteministeriet blev herefter frifundet. ']\n",
      "matches with D_2133410\n",
      "['Sagen angik, hvorvidt sagsøgeren havde krav på yderligere fradrag for udgifter til etablering af intern kloakforsyning og fradrag for udgifter til etablering af intern varmeforsyning.', 'Sagsøgeren fik ikke medhold i, at sagsøgeren var berettiget til yderligere fradrag for det interne kloakforsyningsanlæg, idet de af sagsøgeren markerede kloakforsyningsledninger ikke udgjorde et fradragsberettiget hovedanlæg. Retten lagde herved vægt på, at de pågældende kloakforsyningsledninger nøje fulgte bebyggelsens forløb.', 'For så vidt angår intern varmeforsyning fandt retten ikke, at anlægget udgjorde et fradragsberettiget hovedanlæg. Retten lagde vægt på, at der var tale om et selvstændigt varmeforsyningsanlæg, der var dimensioneret til det konkrete byggeri.', 'Skatteministeriet blev derfor frifundet.']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for doc_id, items in embeddings_dict_new.items():\n",
    "    if i > 2:\n",
    "        break\n",
    "    doc_features = items[\"dist\"]\n",
    "    print(f\"query text: {paragraph_dict[doc_id]}\")\n",
    "    best_match_id = get_best_match(doc_features, tree, doc_index_dict)\n",
    "    print(f\"matches with {best_match_id}\")\n",
    "    print(paragraph_dict[best_match_id])\n",
    "    print(\"\\n\")\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6f86e4359b2b5cf5d398b363c816bb50d8f4fd2c9e9291492e7c9219700f63c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('bertopic_explore': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
