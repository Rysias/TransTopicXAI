{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitatitive topic evaluations\n",
    "This notebook is used for formatting the data for qualitative evaluations. This includes: \n",
    "- Inspecting the topic words\n",
    "- Inspecting representative documents\n",
    "- Coming up with good \"titles\" for the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pprint import pprint\n",
    "from typing import Dict, Tuple, List, Union\n",
    "from bertopic import BERTopic\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def get_model_name(model_path: Path) -> str:\n",
    "    return re.match(\"\\w+-\\w+-\\d+\", model_path.name).group()\n",
    "\n",
    "def create_topic_dict(raw_topic_dict: Dict[int, Tuple[str, int]]) -> Dict[int, List[str]]:\n",
    "    return {k: [tup[0] for tup in lst] for k, lst in raw_topic_dict.items() if k!=-1}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../data\")\n",
    "MODEL_DIR = Path(\"../../ExplainlpTwitter/output\")\n",
    "\n",
    "model_path = next(MODEL_DIR.glob(\"*topic_model*\"))\n",
    "model = BERTopic.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>prob</th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>wants to compete! i want hard competition! i w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.960256</td>\n",
       "      <td>It seems we are stuck on the ground in Amarill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>where the f are my pinking shears? rarararrrar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0ff t0 tHE MEEtiN..  i HAtE WhEN PPl V0lUNtEER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.794290</td>\n",
       "      <td>@ reply me pls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>@user Kind of...I am really annoyed I missed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>So I went to Bahama Bucks today and the cute s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Cold one moment. Sweating the other. Feeling s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>The kids are too cute for my own good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0 earthquake! All is fine, but I had to hold...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99999 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic      prob                                                doc\n",
       "0         -1  0.000000  wants to compete! i want hard competition! i w...\n",
       "1          0  0.960256  It seems we are stuck on the ground in Amarill...\n",
       "2         -1  0.000000  where the f are my pinking shears? rarararrrar...\n",
       "3         -1  0.000000  0ff t0 tHE MEEtiN..  i HAtE WhEN PPl V0lUNtEER...\n",
       "4          3  0.794290                                    @ reply me pls \n",
       "...      ...       ...                                                ...\n",
       "99994      2  1.000000  @user Kind of...I am really annoyed I missed t...\n",
       "99995     -1  0.000000  So I went to Bahama Bucks today and the cute s...\n",
       "99996     -1  0.000000  Cold one moment. Sweating the other. Feeling s...\n",
       "99997     -1  0.000000          The kids are too cute for my own good... \n",
       "99998     -1  0.000000  5.0 earthquake! All is fine, but I had to hold...\n",
       "\n",
       "[99999 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topics = pd.read_csv(MODEL_DIR / \"doc_topics.csv\")\n",
    "doc_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at topic words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['dont',\n",
      "     'http',\n",
      "     'know',\n",
      "     'just',\n",
      "     'like',\n",
      "     'lol',\n",
      "     'http user',\n",
      "     'im',\n",
      "     'think',\n",
      "     'twitter'],\n",
      " 1: ['going',\n",
      "     'day',\n",
      "     'today',\n",
      "     'got',\n",
      "     'bed',\n",
      "     'tomorrow',\n",
      "     'just',\n",
      "     'night',\n",
      "     'time',\n",
      "     'good'],\n",
      " 2: ['im',\n",
      "     'good',\n",
      "     'day',\n",
      "     'going',\n",
      "     'sad',\n",
      "     'today',\n",
      "     'got',\n",
      "     'like',\n",
      "     'just',\n",
      "     'work'],\n",
      " 3: ['user thanks',\n",
      "     'thanks',\n",
      "     'miss',\n",
      "     'thank',\n",
      "     'follow',\n",
      "     'http',\n",
      "     'welcome',\n",
      "     'hey',\n",
      "     'http user',\n",
      "     'know'],\n",
      " 4: ['im',\n",
      "     'lol',\n",
      "     'good',\n",
      "     'haha',\n",
      "     'like',\n",
      "     'just',\n",
      "     'better',\n",
      "     'day',\n",
      "     'dont',\n",
      "     'going'],\n",
      " 5: ['love',\n",
      "     'good',\n",
      "     'fun',\n",
      "     'day',\n",
      "     'great',\n",
      "     'im',\n",
      "     'work',\n",
      "     'nice',\n",
      "     'time',\n",
      "     'like'],\n",
      " 6: ['work',\n",
      "     'hate',\n",
      "     'want',\n",
      "     'im',\n",
      "     'today',\n",
      "     'dont',\n",
      "     'sick',\n",
      "     'day',\n",
      "     'really',\n",
      "     'school'],\n",
      " 7: ['good',\n",
      "     'good morning',\n",
      "     'morning',\n",
      "     'day',\n",
      "     'happy',\n",
      "     'feeling',\n",
      "     'great',\n",
      "     'today',\n",
      "     'hate',\n",
      "     'night'],\n",
      " 8: ['love',\n",
      "     'amazing',\n",
      "     'great',\n",
      "     'awesome',\n",
      "     'wait',\n",
      "     'best',\n",
      "     'happy',\n",
      "     'guys',\n",
      "     'good',\n",
      "     'lt3'],\n",
      " 9: ['good',\n",
      "     '100',\n",
      "     'followers',\n",
      "     'good morning',\n",
      "     'day',\n",
      "     'morning',\n",
      "     'user happy',\n",
      "     'hope',\n",
      "     'happy',\n",
      "     'great']}\n"
     ]
    }
   ],
   "source": [
    "topic_dict = create_topic_dict(model.get_topics())\n",
    "pprint(topic_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob</th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>75824</td>\n",
       "      <td>75824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6600</td>\n",
       "      <td>6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3372</td>\n",
       "      <td>3372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3166</td>\n",
       "      <td>3166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3020</td>\n",
       "      <td>3020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2541</td>\n",
       "      <td>2541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1407</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1308</td>\n",
       "      <td>1308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>940</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>936</td>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>885</td>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        prob    doc\n",
       "topic              \n",
       "-1     75824  75824\n",
       " 0      6600   6600\n",
       " 1      3372   3372\n",
       " 2      3166   3166\n",
       " 3      3020   3020\n",
       " 4      2541   2541\n",
       " 5      1407   1407\n",
       " 6      1308   1308\n",
       " 7       940    940\n",
       " 8       936    936\n",
       " 9       885    885"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topics.groupby(\"topic\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating topic 0\n",
      "(\"words = ['dont', 'http', 'know', 'just', 'like', 'lol', 'http user', 'im', \"\n",
      " \"'think', 'twitter']\")\n",
      "examples for topic 0\n",
      "[\"Y&amp;R Daniel Goddard (Cane) and Joshua Morrow (Nick) are on 'The Price is Right' for the Showcase part...if anyone is home \", '@user Never  its on my bebo ', '@user Check out my last Tweet, I know the feeling. ', \"@user haven't seen your friend request yet \"]\n",
      "\n",
      "evaluating topic 1\n",
      "(\"words = ['going', 'day', 'today', 'got', 'bed', 'tomorrow', 'just', 'night', \"\n",
      " \"'time', 'good']\")\n",
      "examples for topic 1\n",
      "['going places in toothache agony ', 'A shelf in the fridge collapsed spilling salad dressing all over the inside. ', 'oh well, better slip now... gnytz everyone ', \"had an AWESOME weekend with my family... now it's monday and we start ALL over \"]\n",
      "\n",
      "evaluating topic 2\n",
      "(\"words = ['im', 'good', 'day', 'going', 'sad', 'today', 'got', 'like', \"\n",
      " \"'just', 'work']\")\n",
      "examples for topic 2\n",
      "[\"@user  I wish I lived in Vegas, but not for the weather. It's be sooo much fun to spiral down into the pits of gambling and hookers &lt;3\", 'Hell to the yea!! I have finished this nothing azz assignment &amp; made dinner. I am finally going to lay it down. Got to get up at 7am ', \"i'm sick for the 3th time, not going to school tomorrow, only going to do the math test \", \"I pray to be only yours, I pray to be only yours, I know that tou're my only hope... \"]\n",
      "\n",
      "evaluating topic 3\n",
      "(\"words = ['user thanks', 'thanks', 'miss', 'thank', 'follow', 'http', \"\n",
      " \"'welcome', 'hey', 'http user', 'know']\")\n",
      "examples for topic 3\n",
      "['@user thank you ', '@user right ', '@user thanks for the 12oclock comment! ', '@user Will keep in mind that one as well, thanks! ']\n",
      "\n",
      "evaluating topic 4\n",
      "(\"words = ['im', 'lol', 'good', 'haha', 'like', 'just', 'better', 'day', \"\n",
      " \"'dont', 'going']\")\n",
      "examples for topic 4\n",
      "['@user There are better cartoon movies out there. &amp; I see you like to broadcast your love life via twitter. LOL ', 'The reason i smile  is still sleep!', 'WHY THE RAINNN IT WAS NICE!! ', 'Once, I told him a story about ghosts being in my room.. For days, he talked about being very afraid. This kid knows how to heal himself. ']\n",
      "\n",
      "evaluating topic 5\n",
      "(\"words = ['love', 'good', 'fun', 'day', 'great', 'im', 'work', 'nice', \"\n",
      " \"'time', 'like']\")\n",
      "examples for topic 5\n",
      "['@user The complete season two is out in September...! Far too long to wait! ', 'great day today- scored the penthouse upgrade, got homework done 6 days early, got my to-do list done, only thing missing is @user ', 'iPhone is an amazing device ... it keeps u connected all the time ..... but I think it is just too expensive ', \"It's 2am. Trying to keep my head up with God even though it gets hard having a precious child and his father is careless. Goodnight all! \"]\n",
      "\n",
      "evaluating topic 6\n",
      "(\"words = ['work', 'hate', 'want', 'im', 'today', 'dont', 'sick', 'day', \"\n",
      " \"'really', 'school']\")\n",
      "examples for topic 6\n",
      "['I want an E75. ', \"I'm so stuupid. :/ Why did I have to do that. \", \"is up at ridiculous o'clock to spend the day in the library! \", 'working is not fun when the sun is out, and i am so sick of dealing with retarded insurance...argh ']\n",
      "\n",
      "evaluating topic 7\n",
      "(\"words = ['good', 'good morning', 'morning', 'day', 'happy', 'feeling', \"\n",
      " \"'great', 'today', 'hate', 'night']\")\n",
      "examples for topic 7\n",
      "['morning tweeps! ', \"happy mother's day! \", 'I hate sunday nights ', 'Today is a very good day ']\n",
      "\n",
      "evaluating topic 8\n",
      "(\"words = ['love', 'amazing', 'great', 'awesome', 'wait', 'best', 'happy', \"\n",
      " \"'guys', 'good', 'lt3']\")\n",
      "examples for topic 8\n",
      "['@user arghhh !!! we could of fallen in loveeeee (8)  you guys rockkkk  !!!!', '@user - try Uber Twitter!!!!!  . U &amp; ur friend TL r so adorable!!!  ', '@user Yesss! I Love them too!  Haha, yeah.. It was the most amazing day of my life seeing Girlicious. Hopefuly they go to Brazil!', \"listening to Bette Davis Eyes by @user Love your voice, Leighton! It's so unique and soothing  xx\"]\n",
      "\n",
      "evaluating topic 9\n",
      "(\"words = ['good', '100', 'followers', 'good morning', 'day', 'morning', 'user \"\n",
      " \"happy', 'hope', 'happy', 'great']\")\n",
      "examples for topic 9\n",
      "['@user  Big smile- congrats on the upcoming audition.', '@user Outlook good ', '@user Good luck  x', '@user Congrats Matthew!!! ']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for top, words in topic_dict.items():\n",
    "    print(f\"evaluating topic {top}\")\n",
    "    pprint(f\"{words = }\")\n",
    "    print(f\"examples for topic {top}\")\n",
    "    example_tweets = doc_topics.loc[doc_topics[\"topic\"] == top, \"doc\"].sample(4, random_state=42).tolist()\n",
    "    print(example_tweets)\n",
    "    print(\"\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6f86e4359b2b5cf5d398b363c816bb50d8f4fd2c9e9291492e7c9219700f63c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('bertopic_explore': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
