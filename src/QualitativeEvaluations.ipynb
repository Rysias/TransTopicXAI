{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitatitive topic evaluations\n",
    "This notebook is used for formatting the data for qualitative evaluations. This includes: \n",
    "- Inspecting the topic words\n",
    "- Inspecting representative documents\n",
    "- Coming up with good \"titles\" for the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhr\\Anaconda3\\envs\\bertopic_explore\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\jhr\\Anaconda3\\envs\\bertopic_explore\\lib\\site-packages\\numpy\\.libs\\libopenblas.4SP5SUA7CBGXUEOC35YP2ASOICYYEQZZ.gfortran-win_amd64.dll\n",
      "C:\\Users\\jhr\\Anaconda3\\envs\\bertopic_explore\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pprint import pprint\n",
    "from typing import Dict, Tuple, List, Union\n",
    "from bertopic import BERTopic\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def get_model_name(model_path: Path) -> str:\n",
    "    return re.match(\"\\w+-\\w+-\\d+\", model_path.name).group()\n",
    "\n",
    "def create_topic_dict(raw_topic_dict: Dict[int, Tuple[str, int]]) -> Dict[int, List[str]]:\n",
    "    return {k: [tup[0] for tup in lst] for k, lst in raw_topic_dict.items() if k!=-1}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../data\")\n",
    "MODEL_DIR = Path(\"../../ExplainlpTwitter/output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"\"\n",
    "model = BERTopic.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc_topics = pd.read_csv(next(DATA_DIR.glob(\"*full_doc_topics_*.csv\")), index_col=0)\n",
    "doc_topics\n",
    "topic_words = read_pickle(DATA_DIR / \"topic_words.pkl\" )\n",
    "clean_tweets = pd.read_csv(MODEL_DIR / \"clean_tweets.csv\", usecols=[\"cleantext\"])\n",
    "doc_topics = doc_topics.merge(clean_tweets, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at topic words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['user',\n",
      "     'im',\n",
      "     'just',\n",
      "     'good',\n",
      "     'day',\n",
      "     'like',\n",
      "     'http',\n",
      "     'love',\n",
      "     'dont',\n",
      "     'today'],\n",
      " 1: ['user',\n",
      "     'im',\n",
      "     'http',\n",
      "     'just',\n",
      "     'got',\n",
      "     'music',\n",
      "     'new',\n",
      "     'going',\n",
      "     'ill',\n",
      "     'amp'],\n",
      " 2: ['going',\n",
      "     'http',\n",
      "     'user',\n",
      "     'just',\n",
      "     'later',\n",
      "     'house',\n",
      "     'day',\n",
      "     'lunch',\n",
      "     'amp',\n",
      "     'im'],\n",
      " 3: ['user',\n",
      "     'im',\n",
      "     'haha',\n",
      "     'just',\n",
      "     'think',\n",
      "     'time',\n",
      "     'dont',\n",
      "     'ha',\n",
      "     'lol',\n",
      "     'later'],\n",
      " 4: ['user',\n",
      "     'didnt',\n",
      "     'did',\n",
      "     'http',\n",
      "     'think',\n",
      "     'just',\n",
      "     'know',\n",
      "     'twitter',\n",
      "     'like',\n",
      "     'heerens'],\n",
      " 5: ['user',\n",
      "     'june',\n",
      "     '2nd',\n",
      "     'user buy',\n",
      "     'tonight',\n",
      "     'july user',\n",
      "     'today',\n",
      "     '35',\n",
      "     'user friend',\n",
      "     'downloaded'],\n",
      " 6: ['user user', 'user', '', '', '', '', '', '', '', ''],\n",
      " 7: ['user',\n",
      "     'kozha',\n",
      "     'kill',\n",
      "     'think',\n",
      "     'im',\n",
      "     '1999',\n",
      "     'ir',\n",
      "     'days',\n",
      "     'user cuz',\n",
      "     'melt'],\n",
      " 8: ['ill',\n",
      "     'tweet',\n",
      "     'amp',\n",
      "     'today',\n",
      "     'im',\n",
      "     'free',\n",
      "     'user',\n",
      "     'day',\n",
      "     'india',\n",
      "     'single'],\n",
      " 9: ['wwwtweeteraddercom add',\n",
      "     'wwwtweeteraddercom',\n",
      "     'using wwwtweeteraddercom',\n",
      "     'pay vip',\n",
      "     'add train',\n",
      "     'train pay',\n",
      "     'day using',\n",
      "     'followers day',\n",
      "     '100 followers',\n",
      "     'user 100']}\n"
     ]
    }
   ],
   "source": [
    "topic_dict = create_topic_dict(topic_words)\n",
    "pprint(topic_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "-1     410345\n",
       " 0    1161695\n",
       " 1       6137\n",
       " 2       5765\n",
       " 3       4367\n",
       " 4       1348\n",
       " 5       3596\n",
       " 6       2761\n",
       " 7       2549\n",
       " 8        841\n",
       " 9        596\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topics.groupby(\"topic\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prob\n",
       "topic      \n",
       "-1        0\n",
       " 0        0\n",
       " 1        0\n",
       " 2        0\n",
       " 3        0\n",
       " 4        0\n",
       " 5        0\n",
       " 6        0\n",
       " 7        0\n",
       " 8        0\n",
       " 9        0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topics.groupby(\"topic\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "topic_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating topic 0\n",
      "(\"words = ['user', 'im', 'just', 'good', 'day', 'like', 'http', 'love', \"\n",
      " \"'dont', 'today']\")\n",
      "examples for topic 0\n",
      "['http - fucked up eye ', '@user awesome! ', 'no more blonde hair ', \"@user I saw ur pics on FB. Y'all are so cute!  We will ride bikes in Chi. \", \"@user haha, dj's has too much classy stuff cheza! i wanna buy everything there \", 'arrived safely in manila. its nice to be hooome ', \"@user YES. And that's why I think yall're awesome. \", 'The Colours of Southern Africa: the Wildlife Photography of Hannes Lochner http Enjoy and have a fab day  ;)', 'the rain is nice. ', \"man my ankles so effed up. I took a nap and it stopped hurting im scared it'll start hurting again when I walk around \"]\n",
      "\n",
      "evaluating topic 1\n",
      "(\"words = ['user', 'im', 'http', 'just', 'got', 'music', 'new', 'going', \"\n",
      " \"'ill', 'amp']\")\n",
      "examples for topic 1\n",
      "['@user well the molecular twitter party is I believe open to everyone into deleuzian concepts to join in ', '@user well, we have a whole summer!  and even though we live farther away than at scad, it will happen', \"@user I'll have my car if you want lifts  also look @ my co-worker Hillsdon's fbk comments about Download Festival : http\", '@user Yes, it was off to Snoozeville.. when the maintenence started haha ', \"@user Thx.  Still have the eagle pic but just thought I'd put my real pic on since so many others do it too.\", '@user - I saw EpIV in the theater I think 5 times on the original run. ', \"diamond, cupcake, and star's. \", 'is prawn prawn pant. Must finish that pre-production work tonite yet. ', \"@user thanks Claire - I'm building a pollen-free bunker in the middle of the house under the stairs \", \"is on air! Tune in at bailrigg fm in Lancaster or www.bailriggfm.co.uk if you're not  Send in your requests!\"]\n",
      "\n",
      "evaluating topic 2\n",
      "(\"words = ['going', 'http', 'user', 'just', 'later', 'house', 'day', 'lunch', \"\n",
      " \"'amp', 'im']\")\n",
      "examples for topic 2\n",
      "['had a long chat with denise jus now ', \"@user i'm in the hotel Holiday Inn in Cherry Hill in CAMDEN!! \", 'The Boston Terrier puppies have arrived.  5/14/2009.  Mother and litter are well,     http', 'Might be going to Thai Taste... ', '@user @user I left Ramon and Neva at Mocca and Lia went off to play Frisbee at the park. I will give them your regards ', 'Me and @user Last day of school  http', '@user June 7thh  it starts @ 11:30 i believe its at the church! class night is the night before', 'Gon pick the remaining styling 4 project Allround!, &amp; then final rhrsals @ mtv studio with Zircus Zircus, Videoshoot 2mrrow on set ', 'shopping with hailey in the mall ', 'Going to eat mutton tonight. Eat mutton tonight. Get my sheep ribs tonight ']\n",
      "\n",
      "evaluating topic 3\n",
      "(\"words = ['user', 'im', 'haha', 'just', 'think', 'time', 'dont', 'ha', 'lol', \"\n",
      " \"'later']\")\n",
      "examples for topic 3\n",
      "[\"@user Then I have no idea :S. Hahaha I really don't \", 'Facebook-ing LOL then botcha then house chores grrr somebody gotta do it   http', \"@user The pic links are working on my mobile...dunno why you can't see them \", '@user Hummm, made it to work? So *now* we can tweet all day?? ', 'Wish that I was Boulder-bound  #calicon09', '&quot;LINES, VINES AND TRYING TIMES&quot;  Tomorrow!!*  ', \"@user she'd be lke &quot;you just got a phooone&quot; haha and I'm not downloading it eitehr... unless i can't get it for months \", '@user not really haha i just here chillin at home gonna paint my nails all my friends r MIA tonight. ', \"@user - I'm so sorry, but I lolled. Have you eaten anything that makes you particularly flatulent? Been on the fish and chips? lol \", \"I can't as I just joined this company a month ago. No leave except MC. But it's not like I need the hols anyway, so I'll work \"]\n",
      "\n",
      "evaluating topic 4\n",
      "(\"words = ['user', 'didnt', 'did', 'http', 'think', 'just', 'know', 'twitter', \"\n",
      " \"'like', 'heerens']\")\n",
      "examples for topic 4\n",
      "[\"it's just me, the alien and the mickey mouse....   - pig's not even here yet..\", 'is reading through all her AS French stuff just to re jog the old brain ', 'Can someone out there dumb down Invictis oaths for me. Please ', '@user thx  .. but you musnt be envious *shaking head*', \"And the link....as if you didn't know   http\", '@user thems the plan = &quot;wearing them will make you eviler&quot; is my tagline ', '@user  Dude, my name should NOT be listed with those two dudes. Thanks though! ', \"Was following @user &amp; realized we make the same mistake--&quot;...want ya'll to be healthy.&quot; Apparently its y'all not ya'll, y'all \", \"@user haha I was actually bashing my phone and defending another. Ps it's about time you tweet \", '@user yes sir, u do have extremely long arms!! But u had to leave before I got a picture with you ']\n",
      "\n",
      "evaluating topic 5\n",
      "(\"words = ['user', 'june', '2nd', 'user buy', 'tonight', 'july user', 'today', \"\n",
      " \"'35', 'user friend', 'downloaded']\")\n",
      "examples for topic 5\n",
      "['@user am i a top international tweeter ', '@user ready for athens yet? ', 'Place for friends and dating (USERS ONLINE 134.432) http ', '@user , Yea, friadays on a tuesday 12-sharp ', '@user so whos on the show today then phillip?? ', '@user before Friday if possible ', 'http maybe a little of both...  @user', '@user a month I think ', '@user u will recurring HM season 4. ', \"heading out to Cisco's office at Eurocentral for a telepresence meeting with Turkish customers - have to put on a tie \"]\n",
      "\n",
      "evaluating topic 6\n",
      "\"words = ['user user', 'user', '', '', '', '', '', '', '', '']\"\n",
      "examples for topic 6\n",
      "['@user ', '@user ', '@user ', '@user ', '@user  ', '@user ', '@user ', '@user ', 'tweetless ', '@user ']\n",
      "\n",
      "evaluating topic 7\n",
      "(\"words = ['user', 'kozha', 'kill', 'think', 'im', '1999', 'ir', 'days', 'user \"\n",
      " \"cuz', 'melt']\")\n",
      "examples for topic 7\n",
      "[\"@user @user @user I don't care wat you say, but reading my mind about what 4 numbers I just wrote down is not koo at 2am. Scary \", 'Ahh feel ill  If you lie then tell the truth  which is worse the lie or knowing the truth ?', 'my facebook got hacked and started sending viruses to all my friends so dont open weird links from me ', '@user lime is always last.  raspberry was first - but now I am highly allergic.  ', '@user unfortunately I do not know what was coded  suspected of ROR. and get on your ring?', \"@user In the rare case where the mom's not dead, she's either crazy, mean or plain incompetent \", '@user so how badly is the Redfm crew terrorizing the Blackboard Restaurant staff? ', \"@user can you tell to David that I think someone cast a spell on him. it's not fun \", \"@user u really need2 change ur name ur mother didn't  name u Milan mines did.Milan/milano is a italian male name Ugh Blk folks \", 'Cats have stalked and killed a wild pair of Koss ear buds. Rescue came too late - they are beyond hope ']\n",
      "\n",
      "evaluating topic 8\n",
      "(\"words = ['ill', 'tweet', 'amp', 'today', 'im', 'free', 'user', 'day', \"\n",
      " \"'india', 'single']\")\n",
      "examples for topic 8\n",
      "['mtv movie awards tonighttttt ', '@user fast eddie! take me home tonight ', \" Jay's last show in 2 minutes.\", '@user dearface  tomorrow, at lunch... i think im gunna reread twilight whenever gasira gives me my book back ', \"Is wishing that she could be Terrence J's date to the BET awards \", 'doing the andy dance  the one on fonzie gomez show ;) haha', '.@corrisarah777 http  The movie with your favorite history teacher! ', 'Heading out to see Bridget tonight. Cooking dinner and watching wolverine. With vino I hope ', \"@user For you...let's make it Sat! For me, I'll take Wed. \", 'House of kobe!! ']\n",
      "\n",
      "evaluating topic 9\n",
      "(\"words = ['wwwtweeteraddercom add', 'wwwtweeteraddercom', 'using \"\n",
      " \"wwwtweeteraddercom', 'pay vip', 'add train', 'train pay', 'day using', \"\n",
      " \"'followers day', '100 followers', 'user 100']\")\n",
      "examples for topic 9\n",
      "['@user Get 100 followers a day using www.tweeteradder.com Once you add everyone you are on the train or pay vip ', '@user Get 100 followers a day using www.tweeteradder.com Once you add everyone you are on the train or pay vip ', '@user Get 100 followers a day using www.tweeteradder.com Once you add everyone you are on the train or pay vip ', '@user Get 100 followers a day using www.tweeteradder.com Once you add everyone you are on the train or pay vip ', '@user Get 100 followers a day using www.tweeteradder.com Once you add everyone you are on the train or pay vip ', '@user Get 100 followers a day using www.tweeteradder.com Once you add everyone you are on the train or pay vip ', '@user Get 100 followers a day using www.tweeteradder.com Once you add everyone you are on the train or pay vip ', '@user Get 100 followers a day using www.tweeteradder.com Once you add everyone you are on the train or pay vip ', '@user Get 100 followers a day using www.tweeteradder.com Once you add everyone you are on the train or pay vip ', '@user Get 100 followers a day using www.tweeteradder.com Once you add everyone you are on the train or pay vip ']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for top, words in topic_dict.items():\n",
    "    print(f\"evaluating topic {top}\")\n",
    "    pprint(f\"{words = }\")\n",
    "    print(f\"examples for topic {top}\")\n",
    "    example_tweets = doc_topics.loc[doc_topics[\"topic\"] == top, \"cleantext\"].sample(10, random_state=42).tolist()\n",
    "    print(example_tweets)\n",
    "    print(\"\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6f86e4359b2b5cf5d398b363c816bb50d8f4fd2c9e9291492e7c9219700f63c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('bertopic_explore': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
